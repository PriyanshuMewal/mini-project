{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a276e1b-fe6a-4cf5-8878-e721246c8d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\RR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\RR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import mlflow.pyfunc\n",
    "import os\n",
    "import mlflow\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "482e20e1-c50c-485b-b030-6a1c3c29b3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:32: SyntaxWarning: invalid escape sequence '\\]'\n",
      "<>:36: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:32: SyntaxWarning: invalid escape sequence '\\]'\n",
      "<>:36: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\RR\\AppData\\Local\\Temp\\ipykernel_7776\\1559025662.py:32: SyntaxWarning: invalid escape sequence '\\]'\n",
      "  text = re.sub(\"[%s]\" % re.escape(\"\"\"!\"#$%&'()*+,.-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', text)\n",
      "C:\\Users\\RR\\AppData\\Local\\Temp\\ipykernel_7776\\1559025662.py:36: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  text = re.sub('\\s+', ' ', text)\n"
     ]
    }
   ],
   "source": [
    "def lemmatization(text: str) -> str:\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    text = text.split()\n",
    "    text=[lemmatizer.lemmatize(y) for y in text]\n",
    "\n",
    "    return \" \".join(text)\n",
    "\n",
    "def remove_stop_words(text: str) -> str:\n",
    "    try:\n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "    except Exception:\n",
    "        print(\"An error has occurred. If stopwords aren't there please download.\")\n",
    "        raise\n",
    "    else:\n",
    "        text=[i for i in str(text).split() if i not in stop_words]\n",
    "        return \" \".join(text)\n",
    "\n",
    "def removing_numbers(text: str) -> str:\n",
    "    text = \"\".join([i for i in text if not i.isdigit()])\n",
    "    return text\n",
    "\n",
    "def lower_case(text: str) -> str:\n",
    "    text = text.split()\n",
    "\n",
    "    text=[y.lower() for y in text]\n",
    "\n",
    "    return \" \".join(text)\n",
    "\n",
    "def removing_punctuations(text: str) -> str:\n",
    "    ## Remove Punctuations\n",
    "    text = re.sub(\"[%s]\" % re.escape(\"\"\"!\"#$%&'()*+,.-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', text)\n",
    "    text = text.replace(':', \"\")\n",
    "\n",
    "    ## remove extra whitespace\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = \" \".join(text.split())\n",
    "    return text.strip()\n",
    "\n",
    "def removing_urls(text: str) -> str:\n",
    "    url_pattern = re.compile(r\"https?://\\S+|www\\.\\S+\")\n",
    "    return url_pattern.sub(r\"\", text)\n",
    "\n",
    "def normalize_text(content: str) -> str:\n",
    "    content = lower_case(content)\n",
    "    content = remove_stop_words(content)\n",
    "    content = removing_numbers(content)\n",
    "    content = removing_punctuations(content)\n",
    "    content = removing_urls(content)\n",
    "    content = lemmatization(content)\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b864cf01-71f0-4801-b9d9-ce70abc98bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'miss boo another note im soready game come tonight fox grill anyone'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"i miss my boo  on another note im soready for this game to come on tonight...fox grill anyone???!!\"\n",
    "norm_text = normalize_text(text)\n",
    "norm_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26cc6ba3-cd1e-45de-a865-59173c8cf3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/external/emotion_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3555661-7c9a-407b-b6aa-47b7d6060188",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../models/vectorizer.pkl\", \"rb\") as file:\n",
    "    vectorizer = pickle.load(file)\n",
    "\n",
    "text = vectorizer.transform([norm_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4a5a98f-6e9f-4da1-8d2f-29eb7adb5810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>back</th>\n",
       "      <th>day</th>\n",
       "      <th>get</th>\n",
       "      <th>go</th>\n",
       "      <th>going</th>\n",
       "      <th>good</th>\n",
       "      <th>got</th>\n",
       "      <th>happy</th>\n",
       "      <th>http</th>\n",
       "      <th>im</th>\n",
       "      <th>like</th>\n",
       "      <th>lol</th>\n",
       "      <th>miss</th>\n",
       "      <th>one</th>\n",
       "      <th>quot</th>\n",
       "      <th>really</th>\n",
       "      <th>sad</th>\n",
       "      <th>time</th>\n",
       "      <th>today</th>\n",
       "      <th>work</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   back  day  get  go  going  good  got  happy  http  im  like  lol  miss  \\\n",
       "0     0    0    0   0      0     0    0      0     0   1     0    0     1   \n",
       "\n",
       "   one  quot  really  sad  time  today  work  \n",
       "0    0     0       0    0     0      0     0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = pd.DataFrame(text.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35c6b63d-35fa-4ce8-a7d9-fa18d89996da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RR\\Desktop\\Python_Projects2\\MLOps Revisied\\Mini Project\\mini_project\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading artifacts: 100%|█████████████████████████████████████████████████████████████| 5/5 [00:02<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m-64af5c10319c43108e275487c3c61992\n"
     ]
    }
   ],
   "source": [
    "# load model from model registry:\n",
    "dagshub_token = os.getenv(\"DAGSHUB_PAT\")\n",
    "if not dagshub_token:\n",
    "    raise EnvironmentError(\"DAGSHUB_PAT environment variable is not set.\")\n",
    "\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"] = dagshub_token\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = dagshub_token\n",
    "\n",
    "dagshub_url = \"https://dagshub.com\"\n",
    "repo_owner = \"PriyanshuMewal\"\n",
    "repo_name = 'mini-project'\n",
    "\n",
    "mlflow.set_tracking_uri(f\"{dagshub_url}/{repo_owner}/{repo_name}.mlflow\")\n",
    "\n",
    "model_name = \"emotion_detection\"\n",
    "alias = \"champion\"\n",
    "\n",
    "model = mlflow.pyfunc.load_model(model_uri=f\"models:/{model_name}@{alias}\")\n",
    "\n",
    "print(model.model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce2a537c-9bd4-48c6-8b60-67d8df5c4072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ca8fad2-2d17-4751-a7d7-6052c362b4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(text)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e8f8da-61e9-453f-b429-085864983dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.feature_names_in_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
